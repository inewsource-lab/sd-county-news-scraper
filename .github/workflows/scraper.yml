name: San Diego County News Scraper

on:
  schedule:
    # Run every hour at minute 0
    - cron: '0 * * * *'
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape-north:
    runs-on: ubuntu-latest
    name: Scrape North County
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Restore cache
        uses: actions/cache/restore@v4
        id: cache-north
        with:
          path: .cache
          # Unique key per run so we never exact-match; restore-keys gets latest
          key: cache-north-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            cache-north-${{ runner.os }}
      
      - name: Verify cache (North)
        run: |
          echo "Cache hit: ${{ steps.cache-north.outputs.cache-hit }}"
          if [ -f .cache/seen_north.txt ]; then echo "Seen count: $(wc -l < .cache/seen_north.txt)"; else echo "No cache file yet"; fi
      
      - name: Run North County scraper
        env:
          SLACK_WEBHOOK_NORTH: ${{ secrets.SLACK_WEBHOOK_NORTH }}
        run: |
          python scripts/run_scraper.py --region north
      
      - name: Save cache
        uses: actions/cache/save@v4
        if: always()
        with:
          path: .cache
          # Unique key per run to avoid "Unable to reserve cache" when runs overlap
          key: cache-north-${{ runner.os }}-${{ github.run_id }}
      
      - name: Print debug log (North)
        if: always()
        run: |
          if [ -f .cursor/debug.log ]; then echo "--- DEBUG LOG (North) ---"; cat .cursor/debug.log; else echo "No debug log"; fi

  scrape-south:
    runs-on: ubuntu-latest
    name: Scrape South Bay
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Restore cache
        uses: actions/cache/restore@v4
        id: cache-south
        with:
          path: .cache
          key: cache-south-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            cache-south-${{ runner.os }}
      
      - name: Verify cache (South)
        run: |
          echo "Cache hit: ${{ steps.cache-south.outputs.cache-hit }}"
          if [ -f .cache/seen_south.txt ]; then echo "Seen count: $(wc -l < .cache/seen_south.txt)"; else echo "No cache file yet"; fi
      
      - name: Run South Bay scraper
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          python scripts/run_scraper.py --region south
      
      - name: Save cache
        uses: actions/cache/save@v4
        if: always()
        with:
          path: .cache
          key: cache-south-${{ runner.os }}-${{ github.run_id }}
      
      - name: Print debug log (South)
        if: always()
        run: |
          if [ -f .cursor/debug.log ]; then echo "--- DEBUG LOG (South) ---"; cat .cursor/debug.log; else echo "No debug log"; fi
